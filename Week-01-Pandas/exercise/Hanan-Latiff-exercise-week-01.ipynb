{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First print your name in the cell below then save this file. (or something nice about your instructor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hanan Latiff\n"
     ]
    }
   ],
   "source": [
    "# In this cell print your name \n",
    "print('Hanan Latiff' )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data wrangling with Pandas exercise\n",
    "* For this exercise we will be using the `listings.csv` data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/ds-fall-2025-tue/Week-01-Pandas/exercise\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pandas.core.groupby import GroupBy\n",
    "from pandas import Series\n",
    "from pandas.io.formats.style import Styler\n",
    "import os\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in the data file using `pd.read_csv()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>host_id</th>\n",
       "      <th>host_name</th>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>room_type</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>last_review</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2595</td>\n",
       "      <td>Skylit Midtown Castle</td>\n",
       "      <td>2845</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Midtown</td>\n",
       "      <td>40.75362</td>\n",
       "      <td>-73.98377</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>175</td>\n",
       "      <td>3</td>\n",
       "      <td>48</td>\n",
       "      <td>2019-11-04</td>\n",
       "      <td>0.37</td>\n",
       "      <td>2</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3831</td>\n",
       "      <td>Whole flr w/private bdrm, bath &amp; kitchen(pls r...</td>\n",
       "      <td>4869</td>\n",
       "      <td>LisaRoxanne</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Clinton Hill</td>\n",
       "      <td>40.68514</td>\n",
       "      <td>-73.95976</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>340</td>\n",
       "      <td>2020-08-01</td>\n",
       "      <td>4.75</td>\n",
       "      <td>1</td>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5121</td>\n",
       "      <td>BlissArtsSpace!</td>\n",
       "      <td>7356</td>\n",
       "      <td>Garon</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Bedford-Stuyvesant</td>\n",
       "      <td>40.68688</td>\n",
       "      <td>-73.95596</td>\n",
       "      <td>Private room</td>\n",
       "      <td>60</td>\n",
       "      <td>29</td>\n",
       "      <td>50</td>\n",
       "      <td>2019-12-02</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5136</td>\n",
       "      <td>Spacious Brooklyn Duplex, Patio + Garden</td>\n",
       "      <td>7378</td>\n",
       "      <td>Rebecca</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Sunset Park</td>\n",
       "      <td>40.66120</td>\n",
       "      <td>-73.99423</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>175</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5178</td>\n",
       "      <td>Large Furnished Room Near B'way</td>\n",
       "      <td>8967</td>\n",
       "      <td>Shunichi</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Hell's Kitchen</td>\n",
       "      <td>40.76489</td>\n",
       "      <td>-73.98493</td>\n",
       "      <td>Private room</td>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "      <td>473</td>\n",
       "      <td>2020-03-15</td>\n",
       "      <td>3.44</td>\n",
       "      <td>1</td>\n",
       "      <td>340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                               name  host_id  \\\n",
       "0  2595                              Skylit Midtown Castle     2845   \n",
       "1  3831  Whole flr w/private bdrm, bath & kitchen(pls r...     4869   \n",
       "2  5121                                    BlissArtsSpace!     7356   \n",
       "3  5136           Spacious Brooklyn Duplex, Patio + Garden     7378   \n",
       "4  5178                   Large Furnished Room Near B'way　     8967   \n",
       "\n",
       "     host_name neighbourhood_group       neighbourhood  latitude  longitude  \\\n",
       "0     Jennifer           Manhattan             Midtown  40.75362  -73.98377   \n",
       "1  LisaRoxanne            Brooklyn        Clinton Hill  40.68514  -73.95976   \n",
       "2        Garon            Brooklyn  Bedford-Stuyvesant  40.68688  -73.95596   \n",
       "3      Rebecca            Brooklyn         Sunset Park  40.66120  -73.99423   \n",
       "4     Shunichi           Manhattan      Hell's Kitchen  40.76489  -73.98493   \n",
       "\n",
       "         room_type  price  minimum_nights  number_of_reviews last_review  \\\n",
       "0  Entire home/apt    175               3                 48  2019-11-04   \n",
       "1  Entire home/apt     75               1                340  2020-08-01   \n",
       "2     Private room     60              29                 50  2019-12-02   \n",
       "3  Entire home/apt    175              14                  1  2014-01-02   \n",
       "4     Private room     65               2                473  2020-03-15   \n",
       "\n",
       "   reviews_per_month  calculated_host_listings_count  availability_365  \n",
       "0               0.37                               2               365  \n",
       "1               4.75                               1               265  \n",
       "2               0.37                               1               365  \n",
       "3               0.01                               1               295  \n",
       "4               3.44                               1               340  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data here\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/listings.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 - Filtering\n",
    "\n",
    "Return the following subsets of the dataframe.\n",
    "\n",
    "1. How many listings are there with a price less than 100? \n",
    "\n",
    "\n",
    "2. Find how many listings there are in just Brooklyn.\n",
    "\n",
    "\n",
    "3. Find how many listings there are in Brooklyn with a price less than 100.\n",
    "\n",
    "\n",
    "4. Using `.isin()` select anyone that has the host name of Michael, David, John, and Daniel.\n",
    "\n",
    "\n",
    "5. Create a new column called `adjusted_price` that has $100 added to every listing in Williamsburg.  The prices for all other listings should be the same as the were before. \n",
    "\n",
    "\n",
    "6. What % of the rooms are private, and what % of the rooms are shared.  \n",
    "    * Hint, use `.value_counts()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(22778)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. How many listings are there with a price less than 100? \n",
    "\n",
    "num_listings_under_100 = (df[\"price\"] < 100).sum()\n",
    "num_listings_under_100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18632"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Make a new DataFrame of listings in Brooklyn named `df_bk` \n",
    "# and find how many listings in just Brooklyn.\n",
    "\n",
    "df_bk = df[df[\"neighbourhood_group\"] == \"Brooklyn\"]\n",
    "\n",
    "\n",
    "num_bk_listings = len(df_bk)\n",
    "num_bk_listings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18632"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Find how many listings there are in Brooklyn with a price less than 100.\n",
    "\n",
    "df_bk = df[df[\"neighbourhood_group\"] == \"Brooklyn\"]\n",
    "\n",
    "num_bk_listings = len(df_bk)\n",
    "num_bk_listings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1258"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Using `.isin()` select anyone that has the host name of Michael, David, John, and Daniel.\n",
    "# How many total are there that have those names\n",
    "hosts = [\"Michael\", \"David\", \"John\", \"Daniel\"]\n",
    "df_hosts = df[df[\"host_name\"].isin(hosts)]\n",
    "\n",
    "num_hosts = len(df_hosts)\n",
    "num_hosts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>price</th>\n",
       "      <th>adjusted_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Williamsburg</td>\n",
       "      <td>109</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Williamsburg</td>\n",
       "      <td>299</td>\n",
       "      <td>399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Williamsburg</td>\n",
       "      <td>131</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Williamsburg</td>\n",
       "      <td>175</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Williamsburg</td>\n",
       "      <td>80</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   neighbourhood  price  adjusted_price\n",
       "11  Williamsburg    109             209\n",
       "15  Williamsburg    299             399\n",
       "35  Williamsburg    131             231\n",
       "38  Williamsburg    175             275\n",
       "42  Williamsburg     80             180"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. Create a new column called `adjusted_price` that has $100 added to every listing in Williamsburg.  \n",
    "# The prices for all other listings should be the same as the were before. \n",
    "\n",
    "df[\"adjusted_price\"] = np.where(\n",
    "    df[\"neighbourhood\"] == \"Williamsburg\",\n",
    "    df[\"price\"] + 100,\n",
    "    df[\"price\"]\n",
    ")\n",
    "\n",
    "\n",
    "df[df[\"neighbourhood\"] == \"Williamsburg\"][[\"neighbourhood\", \"price\", \"adjusted_price\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "room_type\n",
       "Entire home/apt    51.578653\n",
       "Private room       45.444581\n",
       "Shared room         2.121349\n",
       "Hotel room          0.855417\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. What % of the rooms are private, and what % of the rooms are shared.  \n",
    "\n",
    "room_percentages = df[\"room_type\"].value_counts(normalize=True) * 100\n",
    "room_percentages\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3 - Grouping\n",
    "\n",
    "1. Using `groupby`, count how many listings are in each neighbourhood_group.\n",
    "\n",
    "\n",
    "2. Using `groupby`, find the mean price for each of the neighbourhood_groups. \n",
    "\n",
    "\n",
    "3. Using `groupby` and `.agg()`, find the min and max price for each of the neighbourhood_groups. \n",
    "\n",
    "\n",
    "4. Using `groupby`, find the median price for each room type in each neighbourhood_group.\n",
    "\n",
    "\n",
    "5. Using `groupby` and `.agg()`, find the count, min, max, mean, median, and std of the prices for each room type in each neighbourhood_group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neighbourhood_group\n",
       "Bronx             1183\n",
       "Brooklyn         18632\n",
       "Manhattan        20580\n",
       "Queens            5791\n",
       "Staten Island      341\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Using `groupby`, count how many listings are in each neighbourhood_group.\n",
    "\n",
    "counts = df.groupby(\"neighbourhood_group\").size()\n",
    "counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neighbourhood_group\n",
       "Bronx             92.751479\n",
       "Brooklyn         120.225258\n",
       "Manhattan        191.880466\n",
       "Queens            99.754965\n",
       "Staten Island    110.947214\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Using `groupby`, find the mean price for each of the neighbourhood_groups. \n",
    "mean_prices = df.groupby(\"neighbourhood_group\")[\"price\"].mean()\n",
    "mean_prices\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "room_type\n",
       "Entire home/apt    199.395950\n",
       "Hotel room         275.015075\n",
       "Private room        91.453084\n",
       "Shared room         87.063830\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.5. Using `groupby`, find the mean price for each room_type. \n",
    "mean_prices_by_room = df.groupby(\"room_type\")[\"price\"].mean()\n",
    "mean_prices_by_room"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bronx</th>\n",
       "      <td>16</td>\n",
       "      <td>1404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brooklyn</th>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Manhattan</th>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Queens</th>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Staten Island</th>\n",
       "      <td>19</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     min    max\n",
       "neighbourhood_group            \n",
       "Bronx                 16   1404\n",
       "Brooklyn               0  10000\n",
       "Manhattan              0  10000\n",
       "Queens                 0  10000\n",
       "Staten Island         19   1200"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Using `groupby` and `.agg()`, find the min and max price for each of the neighbourhood_groups. \n",
    "min_max_prices = df.groupby(\"neighbourhood_group\")[\"price\"].agg([\"min\", \"max\"])\n",
    "min_max_prices\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neighbourhood_group  room_type      \n",
       "Bronx                Entire home/apt    138.004819\n",
       "                     Private room        68.419668\n",
       "                     Shared room         66.391304\n",
       "Brooklyn             Entire home/apt    171.587687\n",
       "                     Hotel room         147.300000\n",
       "                     Private room        71.291189\n",
       "                     Shared room         57.870091\n",
       "Manhattan            Entire home/apt    231.335572\n",
       "                     Hotel room         292.515670\n",
       "                     Private room       128.277069\n",
       "                     Shared room        111.735084\n",
       "Queens               Entire home/apt    150.168900\n",
       "                     Hotel room         139.058824\n",
       "                     Private room        69.972564\n",
       "                     Shared room         89.891892\n",
       "Staten Island        Entire home/apt    151.720930\n",
       "                     Private room        70.312883\n",
       "                     Shared room         46.000000\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Using `groupby`, find the mean price for each room_type in each neighbourhood_group.\n",
    "mean_prices = df.groupby([\"neighbourhood_group\", \"room_type\"])[\"price\"].mean()\n",
    "mean_prices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <th>room_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Bronx</th>\n",
       "      <th>Entire home/apt</th>\n",
       "      <td>415</td>\n",
       "      <td>25</td>\n",
       "      <td>1404</td>\n",
       "      <td>138.004819</td>\n",
       "      <td>103.0</td>\n",
       "      <td>126.032106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Private room</th>\n",
       "      <td>722</td>\n",
       "      <td>16</td>\n",
       "      <td>700</td>\n",
       "      <td>68.419668</td>\n",
       "      <td>55.0</td>\n",
       "      <td>57.337866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shared room</th>\n",
       "      <td>46</td>\n",
       "      <td>20</td>\n",
       "      <td>800</td>\n",
       "      <td>66.391304</td>\n",
       "      <td>44.0</td>\n",
       "      <td>114.442703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Brooklyn</th>\n",
       "      <th>Entire home/apt</th>\n",
       "      <td>9112</td>\n",
       "      <td>20</td>\n",
       "      <td>10000</td>\n",
       "      <td>171.587687</td>\n",
       "      <td>135.0</td>\n",
       "      <td>236.732843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hotel room</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>399</td>\n",
       "      <td>147.300000</td>\n",
       "      <td>129.0</td>\n",
       "      <td>91.153206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Private room</th>\n",
       "      <td>9159</td>\n",
       "      <td>10</td>\n",
       "      <td>2500</td>\n",
       "      <td>71.291189</td>\n",
       "      <td>60.0</td>\n",
       "      <td>69.023165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shared room</th>\n",
       "      <td>331</td>\n",
       "      <td>15</td>\n",
       "      <td>1500</td>\n",
       "      <td>57.870091</td>\n",
       "      <td>36.0</td>\n",
       "      <td>92.217618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Manhattan</th>\n",
       "      <th>Entire home/apt</th>\n",
       "      <td>12209</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>231.335572</td>\n",
       "      <td>165.0</td>\n",
       "      <td>410.306439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hotel room</th>\n",
       "      <td>351</td>\n",
       "      <td>0</td>\n",
       "      <td>2211</td>\n",
       "      <td>292.515670</td>\n",
       "      <td>210.0</td>\n",
       "      <td>315.924085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Private room</th>\n",
       "      <td>7601</td>\n",
       "      <td>10</td>\n",
       "      <td>10000</td>\n",
       "      <td>128.277069</td>\n",
       "      <td>80.0</td>\n",
       "      <td>448.677306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shared room</th>\n",
       "      <td>419</td>\n",
       "      <td>10</td>\n",
       "      <td>10000</td>\n",
       "      <td>111.735084</td>\n",
       "      <td>60.0</td>\n",
       "      <td>502.728868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Queens</th>\n",
       "      <th>Entire home/apt</th>\n",
       "      <td>2090</td>\n",
       "      <td>10</td>\n",
       "      <td>10000</td>\n",
       "      <td>150.168900</td>\n",
       "      <td>115.0</td>\n",
       "      <td>252.606739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hotel room</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>249</td>\n",
       "      <td>139.058824</td>\n",
       "      <td>149.0</td>\n",
       "      <td>50.743806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Private room</th>\n",
       "      <td>3499</td>\n",
       "      <td>18</td>\n",
       "      <td>9000</td>\n",
       "      <td>69.972564</td>\n",
       "      <td>55.0</td>\n",
       "      <td>163.814468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shared room</th>\n",
       "      <td>185</td>\n",
       "      <td>14</td>\n",
       "      <td>3000</td>\n",
       "      <td>89.891892</td>\n",
       "      <td>40.0</td>\n",
       "      <td>275.675158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Staten Island</th>\n",
       "      <th>Entire home/apt</th>\n",
       "      <td>172</td>\n",
       "      <td>39</td>\n",
       "      <td>1200</td>\n",
       "      <td>151.720930</td>\n",
       "      <td>111.0</td>\n",
       "      <td>147.518392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Private room</th>\n",
       "      <td>163</td>\n",
       "      <td>20</td>\n",
       "      <td>800</td>\n",
       "      <td>70.312883</td>\n",
       "      <td>55.0</td>\n",
       "      <td>70.759593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shared room</th>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>82</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>38.0</td>\n",
       "      <td>28.446441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     count  min    max        mean  median  \\\n",
       "neighbourhood_group room_type                                                \n",
       "Bronx               Entire home/apt    415   25   1404  138.004819   103.0   \n",
       "                    Private room       722   16    700   68.419668    55.0   \n",
       "                    Shared room         46   20    800   66.391304    44.0   \n",
       "Brooklyn            Entire home/apt   9112   20  10000  171.587687   135.0   \n",
       "                    Hotel room          30    0    399  147.300000   129.0   \n",
       "                    Private room      9159   10   2500   71.291189    60.0   \n",
       "                    Shared room        331   15   1500   57.870091    36.0   \n",
       "Manhattan           Entire home/apt  12209    0  10000  231.335572   165.0   \n",
       "                    Hotel room         351    0   2211  292.515670   210.0   \n",
       "                    Private room      7601   10  10000  128.277069    80.0   \n",
       "                    Shared room        419   10  10000  111.735084    60.0   \n",
       "Queens              Entire home/apt   2090   10  10000  150.168900   115.0   \n",
       "                    Hotel room          17    0    249  139.058824   149.0   \n",
       "                    Private room      3499   18   9000   69.972564    55.0   \n",
       "                    Shared room        185   14   3000   89.891892    40.0   \n",
       "Staten Island       Entire home/apt    172   39   1200  151.720930   111.0   \n",
       "                    Private room       163   20    800   70.312883    55.0   \n",
       "                    Shared room          6   19     82   46.000000    38.0   \n",
       "\n",
       "                                            std  \n",
       "neighbourhood_group room_type                    \n",
       "Bronx               Entire home/apt  126.032106  \n",
       "                    Private room      57.337866  \n",
       "                    Shared room      114.442703  \n",
       "Brooklyn            Entire home/apt  236.732843  \n",
       "                    Hotel room        91.153206  \n",
       "                    Private room      69.023165  \n",
       "                    Shared room       92.217618  \n",
       "Manhattan           Entire home/apt  410.306439  \n",
       "                    Hotel room       315.924085  \n",
       "                    Private room     448.677306  \n",
       "                    Shared room      502.728868  \n",
       "Queens              Entire home/apt  252.606739  \n",
       "                    Hotel room        50.743806  \n",
       "                    Private room     163.814468  \n",
       "                    Shared room      275.675158  \n",
       "Staten Island       Entire home/apt  147.518392  \n",
       "                    Private room      70.759593  \n",
       "                    Shared room       28.446441  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. Using `groupby` and `.agg()`, find the count, min, max, mean, median, and std of the prices \n",
    "# for each room type in each neighbourhood_group.\n",
    "price_stats = df.groupby([\"neighbourhood_group\", \"room_type\"])[\"price\"].agg(\n",
    "    count=\"count\",\n",
    "    min=\"min\",\n",
    "    max=\"max\",\n",
    "    mean=\"mean\",\n",
    "    median=\"median\",\n",
    "    std=\"std\"\n",
    ")\n",
    "\n",
    "price_stats\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load, Merge, and Export files.\n",
    "1. Load the `prices.csv` and the `n_listings.csv`\n",
    "    * Having an error..? Inspect the actual csv file if you're having trouble\n",
    "\n",
    "2. Do join that keeps all the records for each table.\n",
    "    * Neighbourhood groups should include ['Bronx', 'Brooklyn', 'Manhattan', 'Queens', 'Staten Island',\n",
    "       'LongIsland']\n",
    "\n",
    "       \n",
    "3. Save your joined csv as `joined.csv` into the data folder. \n",
    "\n",
    "\n",
    "4. Load your saved table and see if it looks the same or different that the DataFrame you used to create it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prices CSV:\n",
      "  neighbourhood_group   mean_price\n",
      "0               Bronx    92.751479\n",
      "1            Brooklyn   120.225258\n",
      "2           Manhattan   191.880466\n",
      "3              Queens    99.754965\n",
      "4       Staten Island   110.947214 \n",
      "\n",
      "N_listings CSV:\n",
      "  neighbourhood_group;n_listings\n",
      "0                     Bronx;1183\n",
      "1                 Brooklyn;18632\n",
      "2                Manhattan;20580\n",
      "3                LongIsland;4121\n"
     ]
    }
   ],
   "source": [
    "# 1. Load the `prices.csv` and the `n_listings.csv`\n",
    "\n",
    "prices = pd.read_csv(\"../data/prices.csv\")\n",
    "n_listings = pd.read_csv(\"../data/n_listings.csv\")\n",
    "\n",
    "print(\"Prices CSV:\")\n",
    "print(prices.head(), \"\\n\")\n",
    "print(\"N_listings CSV:\")\n",
    "print(n_listings.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['neighbourhood_group', ' mean_price'], dtype='object')\n",
      "Index(['neighbourhood_group', 'n_listings'], dtype='object')\n",
      "  neighbourhood_group  n_listings\n",
      "0               Bronx        1183\n",
      "1            Brooklyn       18632\n",
      "2           Manhattan       20580\n",
      "3          LongIsland        4121\n"
     ]
    }
   ],
   "source": [
    "print(prices.columns)\n",
    "print(n_listings.columns)\n",
    "n_listings = pd.read_csv(\"../data/n_listings.csv\", sep=\";\")\n",
    "print(n_listings.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <th>mean_price</th>\n",
       "      <th>n_listings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bronx</td>\n",
       "      <td>92.751479</td>\n",
       "      <td>1183.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>120.225258</td>\n",
       "      <td>18632.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LongIsland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4121.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>191.880466</td>\n",
       "      <td>20580.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Queens</td>\n",
       "      <td>99.754965</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Staten Island</td>\n",
       "      <td>110.947214</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  neighbourhood_group   mean_price  n_listings\n",
       "0               Bronx    92.751479      1183.0\n",
       "1            Brooklyn   120.225258     18632.0\n",
       "2          LongIsland          NaN      4121.0\n",
       "3           Manhattan   191.880466     20580.0\n",
       "4              Queens    99.754965         NaN\n",
       "5       Staten Island   110.947214         NaN"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Do join that keeps all the records for each table.\n",
    "\n",
    "\n",
    "\n",
    "joined = pd.merge(\n",
    "    prices,\n",
    "    n_listings,\n",
    "    on=\"neighbourhood_group\",\n",
    "    how=\"outer\"\n",
    ")\n",
    "\n",
    "joined\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['grammys.csv', 'joined.csv', 'new_listings.csv', 'n_listings.csv', 'listings.csv', 'ufo_sighting_data.csv', 'prices.csv']\n"
     ]
    }
   ],
   "source": [
    "# 3. Save your joined csv as `joined.csv` into the data folder. \n",
    "import os\n",
    "print(os.listdir(\"../data\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <th>mean_price</th>\n",
       "      <th>n_listings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bronx</td>\n",
       "      <td>92.751479</td>\n",
       "      <td>1183.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>120.225258</td>\n",
       "      <td>18632.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LongIsland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4121.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>191.880466</td>\n",
       "      <td>20580.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Queens</td>\n",
       "      <td>99.754965</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  neighbourhood_group   mean_price  n_listings\n",
       "0               Bronx    92.751479      1183.0\n",
       "1            Brooklyn   120.225258     18632.0\n",
       "2          LongIsland          NaN      4121.0\n",
       "3           Manhattan   191.880466     20580.0\n",
       "4              Queens    99.754965         NaN"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Load your newly saved file, see if it looks the same.  If not, try saving with argument `index=False`\n",
    "\n",
    "\n",
    "joined_check = pd.read_csv(\"../data/joined.csv\")\n",
    "\n",
    "print(joined.equals(joined_check))   # should print True if they are the same\n",
    "\n",
    "joined_check.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Credit\n",
    "Every question below this cell is extra credit and optional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. (Easy) Explore this new PandasAI Package and tell me what its all about because I've never used it. \n",
    "* https://www.youtube.com/watch?v=5w6eZaoDVVk&ab_channel=CodingIsFun  \n",
    "* See if you can use it on the listings.csv to find out some cool info. or answer some of the questions above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandasai\n",
      "  Downloading pandasai-2.3.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting astor<0.9.0,>=0.8.1 (from pandasai)\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting duckdb<2.0.0,>=1.0.0 (from pandasai)\n",
      "  Downloading duckdb-1.3.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting faker<20.0.0,>=19.12.0 (from pandasai)\n",
      "  Downloading Faker-19.13.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.3 in /home/codespace/.local/lib/python3.12/site-packages (from pandasai) (3.1.6)\n",
      "Requirement already satisfied: matplotlib<4.0.0,>=3.7.1 in /home/codespace/.local/lib/python3.12/site-packages (from pandasai) (3.10.3)\n",
      "Collecting openai<2 (from pandasai)\n",
      "  Downloading openai-1.102.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting pandas==1.5.3 (from pandasai)\n",
      "  Downloading pandas-1.5.3.tar.gz (5.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pillow<11.0.0,>=10.1.0 (from pandasai)\n",
      "  Downloading pillow-10.4.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting pydantic<3,>=1 (from pandasai)\n",
      "  Downloading pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting python-dotenv<2.0.0,>=1.0.0 (from pandasai)\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /home/codespace/.local/lib/python3.12/site-packages (from pandasai) (2.32.4)\n",
      "Collecting sqlalchemy<3,>=1.4 (from pandasai)\n",
      "  Downloading sqlalchemy-2.0.43-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting sqlglot<26.0.0,>=25.0.3 (from sqlglot[rs]<26.0.0,>=25.0.3->pandasai)\n",
      "  Downloading sqlglot-25.34.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/codespace/.local/lib/python3.12/site-packages (from pandas==1.5.3->pandasai) (2.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/codespace/.local/lib/python3.12/site-packages (from pandas==1.5.3->pandasai) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.12/site-packages (from pandas==1.5.3->pandasai) (2025.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jinja2<4.0.0,>=3.1.3->pandasai) (3.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib<4.0.0,>=3.7.1->pandasai) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib<4.0.0,>=3.7.1->pandasai) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib<4.0.0,>=3.7.1->pandasai) (4.58.5)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib<4.0.0,>=3.7.1->pandasai) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib<4.0.0,>=3.7.1->pandasai) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib<4.0.0,>=3.7.1->pandasai) (3.2.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from openai<2->pandasai) (4.9.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai<2->pandasai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/codespace/.local/lib/python3.12/site-packages (from openai<2->pandasai) (0.28.1)\n",
      "Collecting jiter<1,>=0.4.0 (from openai<2->pandasai)\n",
      "  Downloading jiter-0.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: sniffio in /home/codespace/.local/lib/python3.12/site-packages (from openai<2->pandasai) (1.3.1)\n",
      "Collecting tqdm>4 (from openai<2->pandasai)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/codespace/.local/lib/python3.12/site-packages (from openai<2->pandasai) (4.14.1)\n",
      "Requirement already satisfied: idna>=2.8 in /home/codespace/.local/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai<2->pandasai) (3.10)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai<2->pandasai) (2025.7.9)\n",
      "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai<2->pandasai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/codespace/.local/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2->pandasai) (0.16.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1->pandasai)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3,>=1->pandasai)\n",
      "  Downloading pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3,>=1->pandasai)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.31.0->pandasai) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.31.0->pandasai) (2.5.0)\n",
      "Collecting greenlet>=1 (from sqlalchemy<3,>=1.4->pandasai)\n",
      "  Downloading greenlet-3.2.4-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting sqlglotrs==0.3.0 (from sqlglot[rs]<26.0.0,>=25.0.3->pandasai)\n",
      "  Downloading sqlglotrs-0.3.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (545 bytes)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.1->pandas==1.5.3->pandasai) (1.17.0)\n",
      "Downloading pandasai-2.3.2-py3-none-any.whl (186 kB)\n",
      "Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Downloading duckdb-1.3.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading Faker-19.13.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading openai-1.102.0-py3-none-any.whl (812 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m812.0/812.0 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (352 kB)\n",
      "Downloading pillow-10.4.0-cp312-cp312-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading sqlalchemy-2.0.43-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sqlglot-25.34.1-py3-none-any.whl (435 kB)\n",
      "Downloading sqlglotrs-0.3.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (327 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading greenlet-3.2.4-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (607 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m607.6/607.6 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Building wheels for collected packages: pandas\n",
      "  Building wheel for pandas (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pandas: filename=pandas-1.5.3-cp312-cp312-linux_x86_64.whl size=45644311 sha256=22783eea0f36bee01d3236a6b3edc645e9898ab54b4a16e99e929194ccd0868c\n",
      "  Stored in directory: /home/codespace/.cache/pip/wheels/fb/83/18/8e7307aa1185c5498c5490e4d9c8a1732d9f1056e86c3491c6\n",
      "Successfully built pandas\n",
      "Installing collected packages: typing-inspection, tqdm, sqlglotrs, sqlglot, python-dotenv, pydantic-core, pillow, jiter, greenlet, duckdb, distro, astor, annotated-types, sqlalchemy, pydantic, pandas, faker, openai, pandasai\n",
      "\u001b[2K  Attempting uninstall: pillow90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/19\u001b[0m [sqlglot]\n",
      "\u001b[2K    Found existing installation: pillow 11.3.0━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/19\u001b[0m [sqlglot]\n",
      "\u001b[2K    Uninstalling pillow-11.3.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/19\u001b[0m [sqlglot]\n",
      "\u001b[2K      Successfully uninstalled pillow-11.3.0━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/19\u001b[0m [pillow]\n",
      "\u001b[2K  Attempting uninstall: pandas━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m14/19\u001b[0m [pydantic]y]\n",
      "\u001b[2K    Found existing installation: pandas 2.3.10m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m14/19\u001b[0m [pydantic]\n",
      "\u001b[2K    Uninstalling pandas-2.3.1:━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m15/19\u001b[0m [pandas]\n",
      "\u001b[2K      Successfully uninstalled pandas-2.3.1m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m15/19\u001b[0m [pandas]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19/19\u001b[0m [pandasai]/19\u001b[0m [pandasai]\n",
      "\u001b[1A\u001b[2KSuccessfully installed annotated-types-0.7.0 astor-0.8.1 distro-1.9.0 duckdb-1.3.2 faker-19.13.0 greenlet-3.2.4 jiter-0.10.0 openai-1.102.0 pandas-1.5.3 pandasai-2.3.2 pillow-10.4.0 pydantic-2.11.7 pydantic-core-2.33.2 python-dotenv-1.1.1 sqlalchemy-2.0.43 sqlglot-25.34.1 sqlglotrs-0.3.0 tqdm-4.67.1 typing-inspection-0.4.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandasai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/pandasai/pipelines/chat/generate_chat_pipeline.py\", line 335, in run\n",
      "    ).run(input)\n",
      "      ^^^^^^^^^^\n",
      "  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/pandasai/pipelines/pipeline.py\", line 137, in run\n",
      "    raise e\n",
      "  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/pandasai/pipelines/pipeline.py\", line 101, in run\n",
      "    step_output = logic.execute(\n",
      "                  ^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/pandasai/pipelines/chat/prompt_generation.py\", line 37, in execute\n",
      "    self.logger.log(f\"Using prompt: {prompt}\")\n",
      "                                    ^^^^^^^^\n",
      "  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/pandasai/prompts/base.py\", line 55, in __str__\n",
      "    return self.to_string()\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/pandasai/prompts/base.py\", line 50, in to_string\n",
      "    self._resolved_prompt = self.prompt.render(**self.props)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/jinja2/environment.py\", line 1295, in render\n",
      "    self.environment.handle_exception()\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/jinja2/environment.py\", line 942, in handle_exception\n",
      "    raise rewrite_traceback_stack(source=source)\n",
      "  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/pandasai/prompts/templates/generate_python_code.tmpl\", line 1, in top-level template code\n",
      "    {% for df in context.dfs %}{% set index = loop.index %}{% include 'shared/dataframe.tmpl' with context %}{% endfor %}\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/pandasai/prompts/templates/shared/dataframe.tmpl\", line 1, in top-level template code\n",
      "    {{ df.to_string(index-1, context.config.direct_sql, context.config.dataframe_serializer, context.config.enforce_privacy) }}\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/pandasai/connectors/base.py\", line 284, in to_string\n",
      "    return DataframeSerializer().serialize(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/pandasai/helpers/dataframe_serializer.py\", line 33, in serialize\n",
      "    return self.convert_df_to_csv(df, extras)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/pandasai/helpers/dataframe_serializer.py\", line 58, in convert_df_to_csv\n",
      "    dataframe_info += f\"\\ndfs[{extras['index']}]:{df.rows_count}x{df.columns_count}\\n{df.to_csv()}\"\n",
      "                                                                                      ^^^^^^^^^^^\n",
      "  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/pandasai/connectors/base.py\", line 265, in to_csv\n",
      "    return self.get_head().to_csv(index=False)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/pandas/util/_decorators.py\", line 333, in wrapper\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/pandas/core/generic.py\", line 3986, in to_csv\n",
      "  File \"/home/codespace/.local/lib/python3.12/site-packages/pandas/io/formats/format.py\", line 987, in to_csv\n",
      "ModuleNotFoundError: No module named 'pandas.io.formats.csvs'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Unfortunately, I was not able to answer your question, because of the following error:\\n\\nNo module named 'pandas.io.formats.csvs'\\n\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandasai import SmartDataframe\n",
    "from pandasai.llm import OpenAI\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/listings.csv\")\n",
    "\n",
    "llm = OpenAI(api_token=\"YOUR_OPENAI_API_KEY\")\n",
    "sdf = SmartDataframe(df, config={\"llm\": llm})\n",
    "\n",
    "sdf.chat(\"What is the average price of listings in Brooklyn?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. (Very Easy) Find other cool Panda packages / add ons and show us what they can do well. And how you installed them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ydata-profiling\n",
      "  Downloading ydata_profiling-4.16.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting scipy<1.16,>=1.4.1 (from ydata-profiling)\n",
      "  Downloading scipy-1.15.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: pandas!=1.4.0,<3.0,>1.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from ydata-profiling) (1.5.3)\n",
      "Collecting matplotlib<=3.10,>=3.5 (from ydata-profiling)\n",
      "  Downloading matplotlib-3.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: pydantic>=2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from ydata-profiling) (2.11.7)\n",
      "Requirement already satisfied: PyYAML<6.1,>=5.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from ydata-profiling) (6.0.2)\n",
      "Requirement already satisfied: jinja2<3.2,>=2.11.1 in /home/codespace/.local/lib/python3.12/site-packages (from ydata-profiling) (3.1.6)\n",
      "Collecting visions<0.8.2,>=0.7.5 (from visions[type_image_path]<0.8.2,>=0.7.5->ydata-profiling)\n",
      "  Downloading visions-0.8.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting numpy<2.2,>=1.16.0 (from ydata-profiling)\n",
      "  Downloading numpy-2.1.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Collecting htmlmin==0.1.12 (from ydata-profiling)\n",
      "  Downloading htmlmin-0.1.12.tar.gz (19 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting phik<0.13,>=0.11.1 (from ydata-profiling)\n",
      "  Downloading phik-0.12.5-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: requests<3,>=2.24.0 in /home/codespace/.local/lib/python3.12/site-packages (from ydata-profiling) (2.32.4)\n",
      "Requirement already satisfied: tqdm<5,>=4.48.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from ydata-profiling) (4.67.1)\n",
      "Requirement already satisfied: seaborn<0.14,>=0.10.1 in /home/codespace/.local/lib/python3.12/site-packages (from ydata-profiling) (0.13.2)\n",
      "Collecting multimethod<2,>=1.4 (from ydata-profiling)\n",
      "  Downloading multimethod-1.12-py3-none-any.whl.metadata (9.6 kB)\n",
      "Collecting statsmodels<1,>=0.13.2 (from ydata-profiling)\n",
      "  Downloading statsmodels-0.14.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
      "Collecting typeguard<5,>=3 (from ydata-profiling)\n",
      "  Downloading typeguard-4.4.4-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting imagehash==4.3.1 (from ydata-profiling)\n",
      "  Downloading ImageHash-4.3.1-py2.py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting wordcloud>=1.9.3 (from ydata-profiling)\n",
      "  Downloading wordcloud-1.9.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting dacite>=1.8 (from ydata-profiling)\n",
      "  Downloading dacite-1.9.2-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting numba<=0.61,>=0.56.0 (from ydata-profiling)\n",
      "  Downloading numba-0.61.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
      "Collecting PyWavelets (from imagehash==4.3.1->ydata-profiling)\n",
      "  Downloading pywavelets-1.9.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: pillow in /usr/local/python/3.12.1/lib/python3.12/site-packages (from imagehash==4.3.1->ydata-profiling) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jinja2<3.2,>=2.11.1->ydata-profiling) (3.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib<=3.10,>=3.5->ydata-profiling) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib<=3.10,>=3.5->ydata-profiling) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib<=3.10,>=3.5->ydata-profiling) (4.58.5)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib<=3.10,>=3.5->ydata-profiling) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib<=3.10,>=3.5->ydata-profiling) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib<=3.10,>=3.5->ydata-profiling) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib<=3.10,>=3.5->ydata-profiling) (2.9.0.post0)\n",
      "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba<=0.61,>=0.56.0->ydata-profiling)\n",
      "  Downloading llvmlite-0.44.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.12/site-packages (from pandas!=1.4.0,<3.0,>1.1->ydata-profiling) (2025.2)\n",
      "Requirement already satisfied: joblib>=0.14.1 in /home/codespace/.local/lib/python3.12/site-packages (from phik<0.13,>=0.11.1->ydata-profiling) (1.5.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2.24.0->ydata-profiling) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2.24.0->ydata-profiling) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2.24.0->ydata-profiling) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2.24.0->ydata-profiling) (2025.7.9)\n",
      "Collecting patsy>=0.5.6 (from statsmodels<1,>=0.13.2->ydata-profiling)\n",
      "  Downloading patsy-1.0.1-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.14.0 in /home/codespace/.local/lib/python3.12/site-packages (from typeguard<5,>=3->ydata-profiling) (4.14.1)\n",
      "Collecting pandas!=1.4.0,<3.0,>1.1 (from ydata-profiling)\n",
      "  Downloading pandas-2.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
      "Requirement already satisfied: attrs>=19.3.0 in /home/codespace/.local/lib/python3.12/site-packages (from visions<0.8.2,>=0.7.5->visions[type_image_path]<0.8.2,>=0.7.5->ydata-profiling) (25.3.0)\n",
      "Requirement already satisfied: networkx>=2.4 in /home/codespace/.local/lib/python3.12/site-packages (from visions<0.8.2,>=0.7.5->visions[type_image_path]<0.8.2,>=0.7.5->ydata-profiling) (3.3)\n",
      "Collecting puremagic (from visions<0.8.2,>=0.7.5->visions[type_image_path]<0.8.2,>=0.7.5->ydata-profiling)\n",
      "  Downloading puremagic-1.30-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas!=1.4.0,<3.0,>1.1->ydata-profiling) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic>=2->ydata-profiling) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic>=2->ydata-profiling) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic>=2->ydata-profiling) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib<=3.10,>=3.5->ydata-profiling) (1.17.0)\n",
      "Downloading ydata_profiling-4.16.1-py2.py3-none-any.whl (400 kB)\n",
      "Downloading ImageHash-4.3.1-py2.py3-none-any.whl (296 kB)\n",
      "Downloading matplotlib-3.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multimethod-1.12-py3-none-any.whl (10 kB)\n",
      "Downloading numba-0.61.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.44.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.1.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading phik-0.12.5-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (679 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m679.7/679.7 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.15.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading statsmodels-0.14.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (10.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typeguard-4.4.4-py3-none-any.whl (34 kB)\n",
      "Downloading visions-0.8.1-py3-none-any.whl (105 kB)\n",
      "Downloading pandas-2.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading dacite-1.9.2-py3-none-any.whl (16 kB)\n",
      "Downloading patsy-1.0.1-py2.py3-none-any.whl (232 kB)\n",
      "Downloading wordcloud-1.9.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (539 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m539.2/539.2 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading puremagic-1.30-py3-none-any.whl (43 kB)\n",
      "Downloading pywavelets-1.9.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: htmlmin\n",
      "  Building wheel for htmlmin (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for htmlmin: filename=htmlmin-0.1.12-py3-none-any.whl size=27161 sha256=b46257b3f88400bf38d61c130becd1c28e11c7e8b8f9a2388a3ff430bd0243ab\n",
      "  Stored in directory: /home/codespace/.cache/pip/wheels/5f/d4/d7/4189b07b5902ee9f3ce0dbb14909fbe8037c39d6c63ffd49c9\n",
      "Successfully built htmlmin\n",
      "Installing collected packages: puremagic, htmlmin, typeguard, numpy, multimethod, llvmlite, dacite, scipy, PyWavelets, patsy, pandas, numba, visions, statsmodels, matplotlib, imagehash, wordcloud, phik, ydata-profiling\n",
      "\u001b[2K  Attempting uninstall: numpy\n",
      "\u001b[2K    Found existing installation: numpy 2.3.1\n",
      "\u001b[2K    Uninstalling numpy-2.3.1:[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/19\u001b[0m [numpy]\n",
      "\u001b[2K      Successfully uninstalled numpy-2.3.1━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/19\u001b[0m [numpy]\n",
      "\u001b[2K  Attempting uninstall: scipy[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/19\u001b[0m [llvmlite]\n",
      "\u001b[2K    Found existing installation: scipy 1.16.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/19\u001b[0m [llvmlite]\n",
      "\u001b[2K    Uninstalling scipy-1.16.0:m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/19\u001b[0m [scipy]\n",
      "\u001b[2K      Successfully uninstalled scipy-1.16.0━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/19\u001b[0m [scipy]\n",
      "\u001b[2K  Attempting uninstall: pandas\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/19\u001b[0m [patsy]lets]\n",
      "\u001b[2K    Found existing installation: pandas 1.5.3━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/19\u001b[0m [patsy]\n",
      "\u001b[2K    Uninstalling pandas-1.5.3:[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/19\u001b[0m [pandas]\n",
      "\u001b[2K      Successfully uninstalled pandas-1.5.3m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/19\u001b[0m [pandas]\n",
      "\u001b[2K  Attempting uninstall: matplotlib━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m13/19\u001b[0m [statsmodels]\n",
      "\u001b[2K    Found existing installation: matplotlib 3.10.3━━━━━━━━━━━━\u001b[0m \u001b[32m13/19\u001b[0m [statsmodels]\n",
      "\u001b[2K    Uninstalling matplotlib-3.10.3:\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m13/19\u001b[0m [statsmodels]\n",
      "\u001b[2K      Successfully uninstalled matplotlib-3.10.3[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m14/19\u001b[0m [matplotlib]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19/19\u001b[0m [ydata-profiling] [ydata-profiling]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pandasai 2.3.2 requires pandas==1.5.3, but you have pandas 2.3.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed PyWavelets-1.9.0 dacite-1.9.2 htmlmin-0.1.12 imagehash-4.3.1 llvmlite-0.44.0 matplotlib-3.10.0 multimethod-1.12 numba-0.61.0 numpy-2.1.3 pandas-2.3.2 patsy-1.0.1 phik-0.12.5 puremagic-1.30 scipy-1.15.3 statsmodels-0.14.5 typeguard-4.4.4 visions-0.8.1 wordcloud-1.9.4 ydata-profiling-4.16.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install ydata-profiling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ImageFilter' from 'PIL' (/home/codespace/.local/lib/python3.12/site-packages/PIL/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[50]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mydata_profiling\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ProfileReport\n\u001b[32m      3\u001b[39m report = ProfileReport(df, title=\u001b[33m\"\u001b[39m\u001b[33mQuick EDA\u001b[39m\u001b[33m\"\u001b[39m, minimal=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      4\u001b[39m report.to_file(\u001b[33m\"\u001b[39m\u001b[33mreport.html\u001b[39m\u001b[33m\"\u001b[39m)         \n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/ydata_profiling/__init__.py:10\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m  \u001b[38;5;66;03m# isort:skip # noqa\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mimportlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutil\u001b[39;00m  \u001b[38;5;66;03m# isort:skip # noqa\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mydata_profiling\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompare_reports\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compare  \u001b[38;5;66;03m# isort:skip # noqa\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mydata_profiling\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcontroller\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pandas_decorator  \u001b[38;5;66;03m# isort:skip # noqa\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mydata_profiling\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprofile_report\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ProfileReport  \u001b[38;5;66;03m# isort:skip # noqa\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/ydata_profiling/compare_reports.py:12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mydata_profiling\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseDescription\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mydata_profiling\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01malerts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Alert\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mydata_profiling\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprofile_report\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ProfileReport\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_should_wrap\u001b[39m(v1: Any, v2: Any) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m     16\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v1, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mdict\u001b[39m)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/ydata_profiling/profile_report.py:26\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtqdm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mauto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtypeguard\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m typechecked\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvisions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VisionsTypeset\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mydata_profiling\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Config, Settings, SparkSettings\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mydata_profiling\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexpectations_report\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExpectationsReport\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/visions/__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"Core functionality\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvisions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m test, types, typesets, utils\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvisions\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackends\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvisions\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdeclarative\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_type\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/visions/utils/__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"Utilities suite for visions\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvisions\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimages\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimage_utils\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvisions\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m monkeypatches\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvisions\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimages\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m image_utils\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/visions/utils/images/__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvisions\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimages\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m image_utils\n\u001b[32m      3\u001b[39m __all__ = [\u001b[33m\"\u001b[39m\u001b[33mimage_utils\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/visions/utils/images/image_utils.py:5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Optional, Tuple, Union\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mimagehash\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExifTags, Image\n\u001b[32m      8\u001b[39m HAS_IMGHDR = import_util.find_spec(\u001b[33m\"\u001b[39m\u001b[33mimghdr\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/imagehash/__init__.py:36\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image, ImageFilter\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     38\u001b[39m \tANTIALIAS = Image.Resampling.LANCZOS\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'ImageFilter' from 'PIL' (/home/codespace/.local/lib/python3.12/site-packages/PIL/__init__.py)"
     ]
    }
   ],
   "source": [
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "report = ProfileReport(df, title=\"Quick EDA\", minimal=True)\n",
    "report.to_file(\"report.html\")         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. (Medium) Use the grammys.csv data for the next section of questions.\n",
    "\n",
    "1. Who was won Album of the Year in 2016?\n",
    "\n",
    "\n",
    "2. Who won Best Rap Album in 2009?\n",
    "\n",
    "\n",
    "3. How many awards was Kendrick Lamar nomiated for, and how many did he win...?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>category</th>\n",
       "      <th>nominee</th>\n",
       "      <th>workers</th>\n",
       "      <th>winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1959</td>\n",
       "      <td>Album of the Year</td>\n",
       "      <td>The Music from Peter Gunn.</td>\n",
       "      <td>Henry Mancini</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1959</td>\n",
       "      <td>Best Album Cover</td>\n",
       "      <td>Only the Lonely</td>\n",
       "      <td>Frank Sinatra (art director)</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1959</td>\n",
       "      <td>Best Arrangement</td>\n",
       "      <td>The Music From Peter Gunn</td>\n",
       "      <td>Henry Mancini (artist/arranger)</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1959</td>\n",
       "      <td>Best Classical Performance - Chamber Music (in...</td>\n",
       "      <td>Beethoven: Quartet 130</td>\n",
       "      <td>The Hollywood String Quartet, Paul Shure (arti...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1959</td>\n",
       "      <td>Best Classical Performance - Instrumentalist (...</td>\n",
       "      <td>Segovia Golden Jubilee</td>\n",
       "      <td>Andrés Segovia</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year                                           category  \\\n",
       "0  1959                                  Album of the Year   \n",
       "1  1959                                   Best Album Cover   \n",
       "2  1959                                   Best Arrangement   \n",
       "3  1959  Best Classical Performance - Chamber Music (in...   \n",
       "4  1959  Best Classical Performance - Instrumentalist (...   \n",
       "\n",
       "                      nominee  \\\n",
       "0  The Music from Peter Gunn.   \n",
       "1             Only the Lonely   \n",
       "2   The Music From Peter Gunn   \n",
       "3      Beethoven: Quartet 130   \n",
       "4      Segovia Golden Jubilee   \n",
       "\n",
       "                                             workers  winner  \n",
       "0                                      Henry Mancini    True  \n",
       "1                       Frank Sinatra (art director)    True  \n",
       "2                    Henry Mancini (artist/arranger)    True  \n",
       "3  The Hollywood String Quartet, Paul Shure (arti...    True  \n",
       "4                                     Andrés Segovia    True  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "grammys = pd.read_csv(\"../data/grammys.csv\")\n",
    "grammys.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>category</th>\n",
       "      <th>nominee</th>\n",
       "      <th>workers</th>\n",
       "      <th>winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5505</th>\n",
       "      <td>2016</td>\n",
       "      <td>Album of the Year</td>\n",
       "      <td>1989.</td>\n",
       "      <td>Taylor Swift (artist/producer), Jack Antonoff ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      year           category nominee  \\\n",
       "5505  2016  Album of the Year   1989.   \n",
       "\n",
       "                                                workers  winner  \n",
       "5505  Taylor Swift (artist/producer), Jack Antonoff ...    True  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammys[(grammys[\"year\"] == 2016) &\n",
    "        (grammys[\"category\"] == \"Album of the Year\") &\n",
    "        (grammys[\"winner\"] == True)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>category</th>\n",
       "      <th>nominee</th>\n",
       "      <th>workers</th>\n",
       "      <th>winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4396</th>\n",
       "      <td>2009</td>\n",
       "      <td>Best Rap Album</td>\n",
       "      <td>Tha Carter III</td>\n",
       "      <td>Lil' Wayne</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      year        category         nominee     workers  winner\n",
       "4396  2009  Best Rap Album  Tha Carter III  Lil' Wayne    True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammys[(grammys[\"year\"] == 2009) &\n",
    "        (grammys[\"category\"] == \"Best Rap Album\") &\n",
    "        (grammys[\"winner\"] == True)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nominated: 2 Won: 1\n"
     ]
    }
   ],
   "source": [
    "kendrick = grammys[grammys[\"nominee\"].str.contains(\"Kendrick Lamar\", case=False, na=False)]\n",
    "\n",
    "nominated = len(kendrick)\n",
    "won = kendrick[\"winner\"].sum()  \n",
    "\n",
    "print(\"Nominated:\", nominated, \"Won:\", won)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Hard) Load the Game Logs for 2022 and add the column names using a dictionary.  \n",
    "* [Link to the data page](https://www.retrosheet.org/gamelogs/)\n",
    "* [Link to the column names](https://procatinator.com/)\n",
    "* haha, gotta find them yourself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['grammys.csv', 'joined.csv', 'new_listings.csv', 'n_listings.csv', 'listings.csv', 'ufo_sighting_data.csv', 'prices.csv']\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/gamelogs_2022.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[59]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(os.listdir(\u001b[33m\"\u001b[39m\u001b[33m../data\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m gamelogs = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../data/gamelogs_2022.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m gamelogs.head()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36m__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36m_make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '../data/gamelogs_2022.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../data\"))\n",
    "\n",
    "gamelogs = pd.read_csv(\"../data/gamelogs_2022.csv\", header=None)\n",
    "gamelogs.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Extra Hard) Download the files for the past 5 years into a new folder and add them all into one data frame using pandas, then save that new file.\n",
    "* Try to not hard code in the file names. We want to do this programmatically because what if we want to add new/more file names in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
