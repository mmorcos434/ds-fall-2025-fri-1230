{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First print your name in the cell below then save this file. (or something nice about your instructor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eric\n"
     ]
    }
   ],
   "source": [
    "# In this cell print your name \n",
    "print(\"Eric\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data wrangling with Pandas exercise\n",
    "* For this exercise we will be using the `listings.csv` data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in the data file using `pd.read_csv()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data here\n",
    "df = pd.read_csv('../data/listings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 - Filtering\n",
    "\n",
    "Return the following subsets of the dataframe.\n",
    "\n",
    "1. How many listings are there with a price less than 100? \n",
    "\n",
    "\n",
    "2. Find how many listings there are in just Brooklyn.\n",
    "\n",
    "\n",
    "3. Find how many listings there are in Brooklyn with a price less than 100.\n",
    "\n",
    "\n",
    "4. Using `.isin()` select anyone that has the host name of Michael, David, John, and Daniel.\n",
    "\n",
    "\n",
    "5. Create a new column called `adjusted_price` that has $100 added to every listing in Williamsburg.  The prices for all other listings should be the same as the were before. \n",
    "\n",
    "\n",
    "6. What % of the rooms are private, and what % of the rooms are shared.  \n",
    "    * Hint, use `.value_counts()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22778\n"
     ]
    }
   ],
   "source": [
    "# 1. How many listings are there with a price less than 100? \n",
    "condition = df['price'] < 100\n",
    "print(len(df[condition]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Make a new DataFrame of listings in Brooklyn named `df_bk` \n",
    "# and find how many listings in just Brooklyn.\n",
    "brooklyn = df['neighbourhood_group'] == 'brooklyn'\n",
    "df_bk = df[brooklyn].copy()\n",
    "print(len(df_bk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# 3. Find how many listings there are in Brooklyn with a price less than 100.\n",
    "df_brookcheap = df[condition & brooklyn].copy()\n",
    "print(len(df_brookcheap))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1258\n"
     ]
    }
   ],
   "source": [
    "# 4. Using `.isin()` select anyone that has the host name of Michael, David, John, and Daniel.\n",
    "# How many total are there that have those names\n",
    "\n",
    "mask = df['host_name'].isin(['Michael', 'David', 'John', 'Daniel'])\n",
    "selected = df[mask]\n",
    "\n",
    "print(len(selected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Create a new column called `adjusted_price` that has $100 added to every listing in Williamsburg.  \n",
    "# The prices for all other listings should be the same as the were before. \n",
    "\n",
    "\n",
    "df['adjusted_price'] = np.where(df['neighbourhood'] == 'Williamsburg', df['price'] + 100, df['price'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12134889419047\n"
     ]
    }
   ],
   "source": [
    "# 6. What % of the rooms are private, and what % of the rooms are shared.  \n",
    "#df.head()\n",
    "total = len(df)\n",
    "condition = df['room_type'] == 'Shared room'\n",
    "amt_shared = len(df[condition].copy())\n",
    "print(amt_shared / total * 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3 - Grouping\n",
    "\n",
    "1. Using `groupby`, count how many listings are in each neighbourhood_group.\n",
    "\n",
    "\n",
    "2. Using `groupby`, find the mean price for each of the neighbourhood_groups. \n",
    "\n",
    "\n",
    "3. Using `groupby` and `.agg()`, find the min and max price for each of the neighbourhood_groups. \n",
    "\n",
    "\n",
    "4. Using `groupby`, find the median price for each room type in each neighbourhood_group.\n",
    "\n",
    "\n",
    "5. Using `groupby` and `.agg()`, find the count, min, max, mean, median, and std of the prices for each room type in each neighbourhood_group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbourhood_group\n",
      "Bronx             1183\n",
      "Brooklyn         18632\n",
      "Manhattan        20580\n",
      "Queens            5791\n",
      "Staten Island      341\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 1. Using `groupby`, count how many listings are in each neighbourhood_group.\n",
    "count_listings = df.groupby('neighbourhood_group').size()\n",
    "#count_listings = df.groupby('neighbourhood_group')   Prints generic PD Object\n",
    "\n",
    "print(count_listings)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbourhood_group\n",
      "Bronx             92.751479\n",
      "Brooklyn         120.225258\n",
      "Manhattan        191.880466\n",
      "Queens            99.754965\n",
      "Staten Island    110.947214\n",
      "Name: price, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 2. Using `groupby`, find the mean price for each of the neighbourhood_groups. \n",
    "mean_prices = df.groupby('neighbourhood_group')['price'].mean()\n",
    "print(mean_prices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "room_type\n",
      "Entire home/apt    23998\n",
      "Hotel room           398\n",
      "Private room       21144\n",
      "Shared room          987\n",
      "dtype: int64\n",
      "room_type\n",
      "Entire home/apt    199.395950\n",
      "Hotel room         275.015075\n",
      "Private room        91.453084\n",
      "Shared room         87.063830\n",
      "Name: price, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 2.5. Using `groupby`, find the mean price for each room_type. \n",
    "print(df.groupby('room_type').size())\n",
    "mean_prices = df.groupby('room_type')['price'].mean()\n",
    "print(mean_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     min    max\n",
      "neighbourhood_group            \n",
      "Bronx                 16   1404\n",
      "Brooklyn               0  10000\n",
      "Manhattan              0  10000\n",
      "Queens                 0  10000\n",
      "Staten Island         19   1200\n"
     ]
    }
   ],
   "source": [
    "# 3. Using `groupby` and `.agg()`, find the min and max price for each of the neighbourhood_groups. \n",
    "\n",
    "#group by neighborhood_groups\n",
    "#for each neighbourhood_group, find the min and max prices\n",
    "by_borough = df.groupby('neighbourhood_group')['price'].agg(['min', 'max'])\n",
    "print(by_borough)\n",
    "\n",
    "#.agg('min', 'max', 'mean')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbourhood_group  room_type      \n",
      "Bronx                Entire home/apt    138.004819\n",
      "                     Private room        68.419668\n",
      "                     Shared room         66.391304\n",
      "Brooklyn             Entire home/apt    171.587687\n",
      "                     Hotel room         147.300000\n",
      "                     Private room        71.291189\n",
      "                     Shared room         57.870091\n",
      "Manhattan            Entire home/apt    231.335572\n",
      "                     Hotel room         292.515670\n",
      "                     Private room       128.277069\n",
      "                     Shared room        111.735084\n",
      "Queens               Entire home/apt    150.168900\n",
      "                     Hotel room         139.058824\n",
      "                     Private room        69.972564\n",
      "                     Shared room         89.891892\n",
      "Staten Island        Entire home/apt    151.720930\n",
      "                     Private room        70.312883\n",
      "                     Shared room         46.000000\n",
      "Name: price, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 4. Using `groupby`, find the mean price for each room_type in each neighbourhood_group.\n",
    "\n",
    "mean_prices = df.groupby(['neighbourhood_group', 'room_type'])['price'].mean()#.reset_index()\n",
    "print(mean_prices)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     min    max  median         std\n",
      "neighbourhood_group room_type                                      \n",
      "Bronx               Entire home/apt   25   1404   103.0  126.032106\n",
      "                    Private room      16    700    55.0   57.337866\n",
      "                    Shared room       20    800    44.0  114.442703\n",
      "Brooklyn            Entire home/apt   20  10000   135.0  236.732843\n",
      "                    Hotel room         0    399   129.0   91.153206\n",
      "                    Private room      10   2500    60.0   69.023165\n",
      "                    Shared room       15   1500    36.0   92.217618\n",
      "Manhattan           Entire home/apt    0  10000   165.0  410.306439\n",
      "                    Hotel room         0   2211   210.0  315.924085\n",
      "                    Private room      10  10000    80.0  448.677306\n",
      "                    Shared room       10  10000    60.0  502.728868\n",
      "Queens              Entire home/apt   10  10000   115.0  252.606739\n",
      "                    Hotel room         0    249   149.0   50.743806\n",
      "                    Private room      18   9000    55.0  163.814468\n",
      "                    Shared room       14   3000    40.0  275.675158\n",
      "Staten Island       Entire home/apt   39   1200   111.0  147.518392\n",
      "                    Private room      20    800    55.0   70.759593\n",
      "                    Shared room       19     82    38.0   28.446441\n"
     ]
    }
   ],
   "source": [
    "# 5. Using `groupby` and `.agg()`, find the count, min, max, mean, median, and std of the prices \n",
    "# for each room type in each neighbourhood_group.\n",
    "\n",
    "price_per_type_per_group = df.groupby(['neighbourhood_group', 'room_type'])['price'].agg(['min', 'max', 'median', 'std'])\n",
    "print(price_per_type_per_group)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load, Merge, and Export files.\n",
    "1. Load the `prices.csv` and the `n_listings.csv`\n",
    "    * Having an error..? Inspect the actual csv file if you're having trouble\n",
    "\n",
    "2. Do join that keeps all the records for each table.\n",
    "    * Neighbourhood groups should include ['Bronx', 'Brooklyn', 'Manhattan', 'Queens', 'Staten Island',\n",
    "       'LongIsland']\n",
    "\n",
    "       \n",
    "3. Save your joined csv as `joined.csv` into the data folder. \n",
    "\n",
    "\n",
    "4. Load your saved table and see if it looks the same or different that the DataFrame you used to create it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the `prices.csv` and the `n_listings.csv`\n",
    "\n",
    "df_prices = pd.read_csv('../data/prices.csv')\n",
    "df_listings = pd.read_csv('../data/n_listings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Do join that keeps all the records for each table.\n",
    "\n",
    "df_merged = df_prices.merge(df_listings, how='outer', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Save your joined csv as `joined.csv` into the data folder. \n",
    "\n",
    "df_merged.to_csv('../data/joined.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  neighbourhood_group   mean_price neighbourhood_group;n_listings\n",
      "0               Bronx    92.751479                     Bronx;1183\n",
      "1            Brooklyn   120.225258                 Brooklyn;18632\n",
      "2           Manhattan   191.880466                Manhattan;20580\n",
      "3              Queens    99.754965                LongIsland;4121\n",
      "4       Staten Island   110.947214                            NaN\n"
     ]
    }
   ],
   "source": [
    "# 4. Load your newly saved file, see if it looks the same.  If not, try saving with argument `index=False`\n",
    "\n",
    "df_loaded = pd.read_csv('../data/joined.csv')\n",
    "print(df_loaded.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Credit\n",
    "Every question below this cell is extra credit and optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandasai\n",
    "from pandasai.llm.openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. (Easy) Explore this new PandasAI Package and tell me what its all about because I've never used it. \n",
    "* https://www.youtube.com/watch?v=5w6eZaoDVVk&ab_channel=CodingIsFun  \n",
    "* See if you can use it on the listings.csv to find out some cool info. or answer some of the questions above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/ufo_sighting_data.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. (Very Easy) Find other cool Panda packages / add ons and show us what they can do well. And how you installed them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Numba needs NumPy 2.1 or less. Got NumPy 2.3.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mydata_profiling\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ProfileReport \n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#pip install ydata_profiling \u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#pip install \"pandas<=2.1\"\u001b[39;00m\n\u001b[32m      5\u001b[39m profile = PortfolioReport(df)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/ydata_profiling/__init__.py:25\u001b[39m\n\u001b[32m     23\u001b[39m spec_numba = importlib.util.find_spec(\u001b[33m\"\u001b[39m\u001b[33mnumba\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m spec_numba \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumba\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01merrors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NumbaDeprecationWarning  \u001b[38;5;66;03m# isort:skip # noqa\u001b[39;00m\n\u001b[32m     27\u001b[39m     warnings.simplefilter(\u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m, category=NumbaDeprecationWarning)\n\u001b[32m     29\u001b[39m display_banner()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/numba/__init__.py:59\u001b[39m\n\u001b[32m     54\u001b[39m             msg = (\u001b[33m\"\u001b[39m\u001b[33mNumba requires SciPy version 1.0 or greater. Got SciPy \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     55\u001b[39m                    \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscipy.__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     56\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m \u001b[43m_ensure_critical_deps\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# END DO NOT MOVE\u001b[39;00m\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# ---------------------- WARNING WARNING WARNING ----------------------------\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_version\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_versions\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/numba/__init__.py:45\u001b[39m, in \u001b[36m_ensure_critical_deps\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m numpy_version > (\u001b[32m2\u001b[39m, \u001b[32m1\u001b[39m):\n\u001b[32m     43\u001b[39m     msg = (\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNumba needs NumPy 2.1 or less. Got NumPy \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     44\u001b[39m            \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumpy_version[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumpy_version[\u001b[32m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     48\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: Numba needs NumPy 2.1 or less. Got NumPy 2.3."
     ]
    }
   ],
   "source": [
    "from ydata_profiling import ProfileReport \n",
    "#pip install ydata_profiling \n",
    "#pip install \"pandas<=2.1\"\n",
    "\n",
    "profile = PortfolioReport(df)\n",
    "profile.to_file(\"report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. (Medium) Use the grammys.csv data for the next section of questions.\n",
    "\n",
    "1. Who was won Album of the Year in 2016?\n",
    "\n",
    "\n",
    "2. Who won Best Rap Album in 2009?\n",
    "\n",
    "\n",
    "3. How many awards was Kendrick Lamar nomiated for, and how many did he win...?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      year           category nominee  \\\n",
      "5505  2016  Album of the Year   1989.   \n",
      "\n",
      "                                                workers  winner  \n",
      "5505  Taylor Swift (artist/producer), Jack Antonoff ...    True  \n",
      "      year        category         nominee     workers  winner\n",
      "4396  2009  Best Rap Album  Tha Carter III  Lil' Wayne    True\n",
      "nominated for 1\n",
      "won 0\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/grammys.csv')\n",
    "\n",
    "year = df['year'] == 2016\n",
    "winner = df['winner'] == True\n",
    "best_album = df['category'] == 'Album of the Year'\n",
    "print(df[winner & year & best_album].copy().head())\n",
    "\n",
    "year = df['year'] == 2009\n",
    "winner = df['winner'] == True\n",
    "best_album = df['category'] == 'Best Rap Album'\n",
    "print(df[winner & year & best_album].copy().head())\n",
    "\n",
    "lamar = df['nominee'] == 'Kendrick Lamar'\n",
    "\n",
    "print(\"nominated for \" + str(len(df[lamar].copy())))\n",
    "print(\"won \" + str(len(df[lamar & winner].copy())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Hard) Load the Game Logs for 2022 and add the column names using a dictionary.  \n",
    "* [Link to the data page](https://www.retrosheet.org/gamelogs/)\n",
    "* [Link to the column names](https://procatinator.com/)\n",
    "* haha, gotta find them yourself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['20220407', '0', 'Thu', 'SDN', 'NL', '1', 'ARI', 'NL.1', '1.1', '2',\n",
      "       ...\n",
      "       'Seth Beer.1', '10.1', 'ellid002', 'Drew Ellis', '5.3', 'perdg001',\n",
      "       'Gerardo Perdomo', '6.4', 'Unnamed: 159', 'Y'],\n",
      "      dtype='object', length=161)\n"
     ]
    }
   ],
   "source": [
    "#https://www.retrosheet.org/gamelogs/glfields.txt\n",
    "\n",
    "pandas_ai = PandasAI(llm)\n",
    "\n",
    "df = pd.read_csv('../data/gl2022.csv')\n",
    "column_descriptions = \"../data/column_names\"\n",
    "\n",
    "content = \"\"\n",
    "with open(column_descriptions, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "prompt = \"based on the descriptions of each column, create a dictionary for each column name: {content}\"\n",
    "\n",
    "response = pandas_ai.run(df, prompt)\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Extra Hard) Download the files for the past 5 years into a new folder and add them all into one data frame using pandas, then save that new file.\n",
    "* Try to not hard code in the file names. We want to do this programmatically because what if we want to add new/more file names in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/pastGames'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m folder_path = \u001b[33m'\u001b[39m\u001b[33m../data/pastGames\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      5\u001b[39m list_dfs = []\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder_path\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m      7\u001b[39m     path = folder_path + \u001b[33m\"\u001b[39m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m + name\n\u001b[32m      8\u001b[39m     df_temp = pd.read_csv(path)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '../data/pastGames'"
     ]
    }
   ],
   "source": [
    "#source: https://pandas.pydata.org/docs/user_guide/merging.html\n",
    "import os \n",
    "\n",
    "folder_path = '../data/pastGames'\n",
    "\n",
    "list_dfs = []\n",
    "for name in os.listdir(folder_path):\n",
    "    path = folder_path + \"/\" + name\n",
    "    df_temp = pd.read_csv(path)\n",
    "    list_dfs.append(df_temp)\n",
    "\n",
    "result = pd.concat(list_dfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
